---
title: "Convention Prediction with a Bayesian Multinomial Model"
output: jekyllthat:jekylldown
---

# Predicting Convention Outcomes

For this project, I'll be predicting the first ballot for Governor results from the 2018 DFL [^1]
Convention. At this convention, I was working for Erin Murphy, one of the candidates, on her data team, and so I have access to their database on the Delegates heading into the convention. A winner is declared if any candidate reaches 60% of the Delegate pool of 1307.5 Delegates, so 785 votes. For simplicity, I focus in this project solely on predicting the first ballot results. Thus, my goals with this project are:

1. Represent my uncertainty about the possible convention outcomes given the data we have intelligently.
2. See how much we can improve predictions by exploiting the hierarchical nature of districts (Party Units within Congressional Districts).
3. See if this makes sense as a modeling strategy to keep developing by adding the individual level data.

[^1]: For historical reasons, the Democratic Party in Minnesota is known as the 
Democratic Farmer Labor party.

# The Dataset

For each of the non-empty 121 Party Units in Minnesota, my response is a vector of Delegate counts that each candidate (Erin Murphy, Rebecca Otto, and Tim Walz) received, along with a count for "No Endorsement" voters. Thus, summing across the 121 PUs would give the full first ballot results by candidate. I thus model these using a **multinomial logit model** in brms.

In terms of predictors, we have the Congressional district each party unit is in, which should explain some variation, as Otto/Walz are generally perceived to be more appealing to rural voters, while Murphy was from the Twin Cities. I also have the estimated proportion of Delegates the Murphy campaign they believed they had the support of in each Party Unit, based on their field campaign, and on the subcaucuses the Delegates were elected out of. These proportions turned out to be quite accurate, and so my assumption is they'll be strong predictors. While I have access to the Delegate level dataset, I didn't have time to clean it fully for use in this series of models.

I excluded the data cleaning from the final PDF, but it's available in the .Rmd. One non-obvious transformation I make is to double all counts before modeling, but halve them before analysis, as some rural, low population areas are awarded "half delegates", and I need integer outcomes to work with a multinomial model.

```{r,include=F}
library(tidyverse)
library(brms)
library(loo)
library(bayesplot)
library(tidybayes)
options(mc.cores = parallel::detectCores())

erin_data <- read.csv("Final Project/Cleaned_erin_data.csv") %>%
  rename(ErinMurphy = Erin.Murphy, RebeccaOtto = Rebecca.Otto, TimWalz = Tim.Walz, NoEndorse = No.Endorse) %>% 
  rename(CD = Ã¯..CD) %>%
  # Roseau didn't manage to get anyone to vote, and multinomial requires positive ints
  filter(Party.Unit != "Roseau") %>% 
  na.omit()

# To make it possible for very low population, rural areas to have representatives,
# there are half delegates; so we run the model after doubling, and return to the
# original scale in the final model.
erin_data$y <- with(erin_data, cbind(2*NoEndorse,2*ErinMurphy,2*RebeccaOtto,2*TimWalz))
erin_data$Total <- with(erin_data, 2*ErinMurphy + 2*RebeccaOtto + 2*TimWalz + 2*NoEndorse)

sumdiv2 <- function(x) {
  sum(x)/2
}

```


# Prior Predictive Simulation: Intercept Only

I start with an intercept only model, and plot realizations of the first ballot
across draws. This helps explain my level of uncertainty before we include predictors
and condition on the data. Since I was running short on pages, I only include this
initial part of building the model generatively at first.

For context on the priors,
there was a relatively large amount of uncertainty for our campaign and all the
campaigns heading into first ballot for a variety of reasons. First, we had
only ID'd about 2/3 of the delegate body by first ballot. Second, it was
becoming increasingly clear that Rebecca Otto didn't have
the delegates to win the convention, so it was possible we'd see a decent
portion of her delegates switch sides even before first ballot. Finally, a major statewide
c4, ISAIAH, had been telling their delegates to hold off on committing until the middle of the convention, but the rumor was that they were going to endorse Erin Murphy's or Otto's
campaign (whichever progressive was more viable), so a large number of Delegates had a preference they didn't openly state.

All that said, while it was highly unlikely that anyone was going to
reach a winning 60% of the delegate pool (785 Delegates) first ballot, I did want at least
a bit of probability on those outcomes. From our ID data, it looked something like
0%-40%-20%-40% was the most likely outcome for the first ballot, which is how I set the means.

As a final note, voting "No Endorsement" on an early ballot is extremely rare, which is correctly reflected.

```{r}

# Base class is No-Endorsement
initial_prior <- c(prior(normal(4,.25), class = "Intercept", dpar = "mu2"),
              prior(normal(3,.5), class = "Intercept", dpar = "mu3"),
              prior(normal(4,.25), class = "Intercept", dpar = "mu4")
              )

int_only <- brm(bf(y | trials(Total) ~ 1), family=multinomial(),data=erin_data, prior = initial_prior, sample_prior="only")

linpred <- posterior_linpred(int_only, transform = T)

# Divide by 2 after summing the totals to put back on original delegate count scale
boxplot(apply(linpred, c(1,3), FUN = sumdiv2), pch = ".", las = 1,
        names = c("No Endorse", "Erin Murphy", "Rebeca Otto", "Tim Walz"))
```

# Initial Posterior

Now let's add in our non-CD predictors and condition on our data. I add a $N(0,3)$ prior over all the $\beta$'s as a weakly informative prior to help the model fit. The model fits well; there are no divergences, all $\hat{R}$ were 1, and I got a good number of effective samples for each parameter.

As we'd expect with so little data, the standard errors are very large compared to the coefficients,
but generally point the right ways- the Strong/Lean Erin predictions have a positive influence on Erin's support (mu2), for example, and similar with Walz (mu4), and Otto (mu2). Later, when I look at marginal plots, I'll talk more about some of the more interesting coefficients, namely the ISAIAH and Unknown ones.

```{r,echo=F}
pred_prior <- c(prior(normal(4,.25), class = "Intercept", dpar = "mu2"),
              prior(normal(3,.5), class = "Intercept", dpar = "mu3"),
              prior(normal(4,.25), class = "Intercept", dpar = "mu4"),
              prior(normal(0,3),class = "b")
              )

intial_post <- brm(bf(y | trials(Total) ~ ISAIAH + Lean.Erin + Lean.Walz + Lean.Otto + Strong.Erin + Strong.Otto +
        Strong.Walz + Undecided + Unknown), family=multinomial(),prior = pred_prior, data=erin_data)

summary(intial_post)
```

# Nesting the Party Units in CD

A next logical step for the model would be to incorporate the multilevel structure
present in the data- Party Units nested within Congressional Districts. Given that
the CD's reflect both the progressive/moderate and rural/urban divides that defined
the election, expecting some significant between group variation is reasonable.

```{r}
final_prior <- c(prior(normal(4,.25), class = "Intercept", dpar = "mu2"),
              prior(normal(3,.5), class = "Intercept", dpar = "mu3"),
              prior(normal(4,.25), class = "Intercept", dpar = "mu4"),
              prior(normal(0,3),class = "b"),
              prior(normal(0,.2), class = "sd", group = "CD", dpar = "mu2"),
              prior(normal(0,.2), class = "sd", group = "CD", dpar = "mu3"),
              prior(normal(0,.2), class = "sd", group = "CD", dpar = "mu4")
              )

full_model <- brm(bf(y | trials(Total) ~ ISAIAH + Lean.Erin + Lean.Walz + Lean.Otto + Strong.Erin + Strong.Otto +
        Strong.Walz + Undecided + Unknown + (1|CD)), family=multinomial(),prior = final_prior, data=erin_data)

summary(full_model)
```

# Model Comparison

Intuitively, a model with pooling across CD's should outperform a single level
model using them, but below I made sure that that is indeed the case- below, the
multilevel level model far outperforms the single level one, with it's ELPD more
than 2 standard errors better.

One limitation of the analysis below is that I wasn't able refit without the final observation (the super delegates) as recommended by the loo package to calculate ELPDs for the super delegates directly. This is because the "Super" level
only exists in 1 example, and loo doesn't allow new factor levels- holding it out thus throws an error.

```{r, echo=F}
unpooled_prior <- c(prior(normal(4,.25), class = "Intercept", dpar = "mu2"),
              prior(normal(3,.5), class = "Intercept", dpar = "mu3"),
              prior(normal(4,.25), class = "Intercept", dpar = "mu4"),
              prior(normal(0,3),class = "b")
              )

not_pooled_model <- brm(bf(y | trials(Total) ~ ISAIAH + Lean.Erin + Lean.Walz + Lean.Otto + Strong.Erin + Strong.Otto +
        Strong.Walz + Undecided + Unknown + CD), family=multinomial(),prior = unpooled_prior, data=erin_data)



loo1 <- loo(full_model, save_psis=T)
loo2 <- loo(not_pooled_model, save_psis=T)

loo_compare(loo1, loo2)

loo_model_weights(list(loo1,loo2))
```



# Interesting Marginal Plots

For the most part, the marginal plots were what I'd expect- for instance, PUs with a greater estimated strong support for Erin ("Strong Erin"), had increasingly greater support for Erin, and vice versa for Walz, and so I don't show most of these.

Even though the predictions are obviously very noisy however, they did pick up on two important, more subtle trends. First, in the ISAIAH plot below, it's beginning to appear that Murphy (2) does well in places with many ISAIAH delegates, whereas Walz (4) does progressively worse. As they didn't formally endorse Erin until between ballots 2 and 3, the model correctly modeling these slopes' directions even without individual level predictors is impressive.

```{r, echo=F}
marginal_effects(full_model, effects = "ISAIAH", categorical = TRUE)
```

The other interesting trend the model picked up on was that it tends to be harder to ID your opponent's supporters than your own- as your supports want to contact and work with the campaign, but the opponents' have no reason to do so, and help their candidate by not giving you much information. This is correctly reflected in the negative slope in Unknown for Erin (2), but positive one for Walz (4), given the predictor data comes from the Murphy campaign.

While these plots suggest a understandably high level of uncertainty, the fact that they're correctly reflecting many of the relationships I believe to be true offers some level of face validity of the model.

```{r, echo=F}
marginal_effects(full_model, effects = "Unknown", categorical = TRUE)
```

# Posterior Predictive Check

Plotting the predictions for Erin Murphy and Tim Walz against the actual results,
we can see the predictions track reasonably closely considering the limited data. While many point predictions fall outside the 25-75 quantile range, the vast majority stay within the boxplot's whiskers. Again, stressing the limitations of the small dataset we have, this is a fairly reasonable range of outcomes to predict, and there's no systematic pattern I can see to which Party Units the model struggles with.

```{r, echo=F}
# Bayesplot and pp_check() in brms both didn't have great support for multinomial
# models, so doing these myself
preds <- posterior_linpred(full_model,transform = T)
plot_data <- as.data.frame(erin_data$y) %>% mutate(id = row_number())
plot_these_Erin <- as.data.frame(preds[,,2])
plot_these_Walz <- as.data.frame(preds[,,4])

ggplot(stack(plot_these_Erin), aes(x = ind, y = values)) +
  geom_boxplot() + annotate("point",x=plot_data$id,y=plot_data$V2, color = "blue") +
  ggtitle("Erin Post by Party Unit") + xlab("Party Unit") + ylab("Delegates")
  

ggplot(stack(plot_these_Walz), aes(x = ind, y = values)) +
  geom_boxplot() + annotate("point",x=plot_data$id,y=plot_data$V4, color = "red") +
  ggtitle("Walz Post by Party Unit") + xlab("Party Unit") + ylab("Delegates")
  
```


# Conclusion

To truly use a model like this, I'd definitely want to fully incorporate the individual level data
that underlie most of my predictors and more, as attempting to model with 1 obs/district is challenging. However, this initial model is fairly promising- nesting PUs within CDs seems like a strong overall strategy, and even with limited data, the model already can pick up on relationships like that between estimated ISAIAH and Unknown support and Delegate returns, and it's by PU predictions are already reasonable.